##Crypto ETL with Apache Airflow
This is a dynamic data pipeline project designed to keep tabs on the ever-changing world of cryptocurrency. Using Apache Airflow, this ETL pipeline pulls hourly snapshots of key metrics like price, market cap, and trading volume for top digital assets â€” then loads them into a PostgreSQL time-series database for analysis.

ğŸŒ What This Project Does
This pipeline automates the full data journey â€” from pulling market data from the CoinGecko API to storing it in a structured format in your database. It's built to run hourly, giving you fresh insights around the clock.

ğŸ” Core Highlights
â± Hourly crypto tracking for 15 top coins like BTC, ETH, SOL, and more

ğŸ“Š Captures price, volume, and market cap for each coin

ğŸ—ƒ Stores results in PostgreSQL under a crypto.crypto_prices table

ğŸ›¡ Robust with retry mechanisms and failure alerts

ğŸ” Secrets like DB credentials managed securely via .env file

ğŸ§° Stack in Use
Tool	             Purpose
Apache Airflow	  Task orchestration & scheduling
Python 3.12      	Core language
CoinGecko API	    Real-time market data source
PostgreSQL	      Analytical data storage
psycopg2	        DB driver
python-dotenv   	Secret management

âš™ï¸ Getting Started
Hereâ€™s how to spin up this pipeline on your local machine:

1. Clone the Repo
git clone https://github.com/your-username/crypto-etl-pipeline.git
cd crypto-etl-pipeline

2. Set Up the Virtual Environment
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

3. Install the Required Packages
pip install -r requirements.txt

4. Configure Secrets
Create a .env file in the root folder:
DB_NAME=defaultdb
DB_HOST=your-db-host.aivencloud.com
DB_USER=avnadmin
DB_PASSWORD=yourpassword
DB_PORT=17440

5. Initialize Airflow
airflow db init

6. Start the Web UI and Scheduler
airflow webserver --port 8080
airflow scheduler

ğŸ§ª How to Test the Pipeline
Open your browser and navigate to http://localhost:8080

Locate the DAG titled coin_price_etl_dag

Toggle it on and trigger a run

Open the logs to trace the data extraction and loading process

ğŸ—‚ Where the Data Goes
Youâ€™ll find the processed data stored in the crypto.crypto_prices table, structured like this:

name	symbol	price	market_cap	total_volume	timestamp

Perfect for dashboards, trading models, or historical analytics.

ğŸ¤ Contributions Welcome
Want to improve the DAG, support new coins, or hook it into a visualization tool? Fork the repo, open a pull request, or drop a suggestion.

ğŸ“¬ Get in Touch
Author: Kelly Kiprop
ğŸ“§ kipropkelly4@gmail.com

ğŸ“œ License
This project is open-sourced under the MIT License. Use it freely and modify as you see fit!
